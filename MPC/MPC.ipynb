{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2eafe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gym\n",
    "from torch.distributions import Normal\n",
    "from gym.spaces import Box\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from torch.distributions import MultivariateNormal\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\Максимилиан\\\\Desktop\\\\Skoltech\\\\Reinforcement learning\\\\Final project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17838e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from casadi import *\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from gekko import GEKKO\n",
    "from Dynamics import get_next_state, state_to_coords, get_energy\n",
    "from Environment import DoublePendulumEnv, normalize_angle\n",
    "from PPO.Proximal_Policy_Optimization import PPO, unscaled_action\n",
    "from PPO.train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238529c5",
   "metadata": {},
   "source": [
    "# MPC based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9446f76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: do-mpc in c:\\programdata\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\максимилиан\\appdata\\roaming\\python\\python38\\site-packages (from do-mpc) (3.6.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from do-mpc) (1.20.1)\n",
      "Requirement already satisfied: casadi in c:\\programdata\\anaconda3\\lib\\site-packages (from do-mpc) (3.5.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->do-mpc) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->do-mpc) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->do-mpc) (4.37.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->do-mpc) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->do-mpc) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->do-mpc) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->do-mpc) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\максимилиан\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib->do-mpc) (21.3)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->do-mpc) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install do-mpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e2ce2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use MPC to control the Pendulum.\n",
    "In this version an additional real model is needed for simulation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# simulate and choose the best action\n",
    "def choose_action(state, rollout, horizon):\n",
    "    \"\"\"\n",
    "    :param rollout: trajectories that are simulated.\n",
    "    :param horizon: steps lookahead.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    best_action = None\n",
    "    max_trajectory_value = -float('inf')\n",
    "    for trajectory in range(rollout):\n",
    "        env.state = state\n",
    "        trajectory_value = 0\n",
    "        for h in range(horizon):\n",
    "            action = np.array([random.uniform(-5, 5)])\n",
    "            if h == 0:\n",
    "                first_action = action\n",
    "            _, reward, _, _ = env.step(action)\n",
    "            trajectory_value += reward\n",
    "        # check if this trajectory's value is higher.\n",
    "        if trajectory_value > max_trajectory_value:\n",
    "            max_trajectory_value = trajectory_value\n",
    "            best_action = first_action\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22837d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    for rollout, horizon in zip(rollout_list, horizon_list):\n",
    "        episode_reward_list = []\n",
    "        for episode in range(max_episodes):\n",
    "            state = env.reset()\n",
    "            episode_reward = 0\n",
    "            for step in range(max_episode_steps):\n",
    "#                 if render:\n",
    "#                     env.render()\n",
    "                state = env.state\n",
    "                action = choose_action(state, rollout, horizon)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                episode_reward += reward\n",
    "            print('episode %d ends with reward %d' % (episode, episode_reward))\n",
    "            episode_reward_list.append(episode_reward)\n",
    "        plt.plot(episode_reward_list, label='rollout=%d horizon=%d' % (rollout, horizon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d89536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment initialized\n"
     ]
    }
   ],
   "source": [
    "state = [0, np.pi/2, np.pi/2, 0, 0, 0]\n",
    "if __name__ == '__main__':\n",
    "    seed = 1000\n",
    "    max_episodes = 10000\n",
    "    max_episode_steps = 500\n",
    "    env = DoublePendulumEnv(init_state = state )\n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    render = True\n",
    "\n",
    "    # custom the rollout number and horizon number\n",
    "    rollout_list = [50]\n",
    "    horizon_list = [10]\n",
    "    start()\n",
    "\n",
    "    env.close()\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('episode')\n",
    "    plt.ylabel('episode reward')\n",
    "    plt.title('MPC_Pendulum_v0')\n",
    "    # plt.savefig('Naive_MPC/MPC_Pendulum_v0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d80d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
